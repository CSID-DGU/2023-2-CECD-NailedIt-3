input {
       # FileBeat를 통해 로그 수신
#        beats {
#                port => 5000
#                host => "0.0.0.0"
#                ssl => false
#        }
       kafka {
               bootstrap_servers => "kafka:9092"
               topics => ["log"]        
               codec => "json"              
       }

}

filter {
       grok {
        match => {
            "message" => "timestamp: %{TIMESTAMP_ISO8601:timestamp}, pH: %{NUMBER:pH}, DO\(PPM\): %{NUMBER:DO}, salinity\(%\): %{NUMBER:salinity}, turbidity\(NTU\): %{NUMBER:turbidity}, ammonia\(mg/L\): %{NUMBER:ammonia}"
        }
    }
       # mutate {
       #        split => { "message" => ","}
       #        add_field => { "timestamp" => "%{[message][0]}"}
       #        add_field => { "pH" => "%{[message][1]}"}
       #        add_field => { "DO(PPM)" => "%{[message][2]}"}
       #        add_field => { "salinity(%)" => "%{[message][3]}"}
       #        add_field => { "turbidity(NTU)" => "%{[message][4]}"}
       #        add_field => { "ammonia(mg/L)" => "%{[message][5]}"}
       #        remove_field => "message"
       # }
}

output {
       # 처리한 로그를 Elastic 서버로 전송
       elasticsearch {
               # TODO 각자의 서버에 맞게 IP 변경
               hosts => "elasticsearch:9200"
               user => "elastic"
               password => "changeme"
       }
}
